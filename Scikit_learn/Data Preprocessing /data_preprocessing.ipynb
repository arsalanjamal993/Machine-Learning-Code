{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9dd6920",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "data = {\n",
    "    'Name':[\"Chatgpt\", \"Grok\", 'Gemini', 'Copilot', 'Claude'],\n",
    "    'Age':[34, 45, None, 23, None],\n",
    "    'Salary':[50000, 80000, None, 300000, None]\n",
    "\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(df)\n",
    "\n",
    "print(df.isnull().sum())\n",
    "\n",
    "df_drop = df.dropna()\n",
    "print(df_drop)\n",
    "\n",
    "df['Age'].fillna(df['Age'].mean(), inplace=True)\n",
    "df['Salary'].fillna(df['Salary'].mean(), inplace=True)\n",
    "\n",
    "print(df.isnull().mean() * 100) # This will show how much % data is missing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91e2c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LABEL ENCODING \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd \n",
    "\n",
    "df = pd.read_csv('/home/developerarsalan/My Code/Machine_Learning_Code/Scikit_learn/data_preprocessing.ipynb')\n",
    "\n",
    "df_label = df.copy()\n",
    "\n",
    "le = LabelEncoder()\n",
    "df_label['Gender_Encoded'] = le.fit_transform(df_label['Gender'])\n",
    "df_label['Passed_Encoded'] = le.fit_transform(df_label['Passed'])\n",
    "\n",
    "print('\\nLabel Encoded Data')\n",
    "print(df_label[['Name', 'Gender', 'Gender_Encoded', 'Passed', 'Passed_Encoded']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507bbe65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONE HOT ENCODING\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd \n",
    "\n",
    "df = pd.read_csv('/home/developerarsalan/My Code/Machine_Learning_Code/Scikit_learn/data_preprocessing.ipynb')\n",
    "\n",
    "df_label = df.copy()\n",
    "\n",
    "df_encoded = pd.get_dummies(df_label, columns=['City'])\n",
    "print('\\n One-hot Encoding Data (city)')\n",
    "print(df_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c5b95545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard Scaler Output:\n",
      "    StudyHours  TestScore\n",
      "0    -1.474087  -1.746067\n",
      "1    -1.127243  -1.227946\n",
      "2    -0.780399  -0.709826\n",
      "3    -0.433555  -0.191705\n",
      "4    -0.086711   0.326416\n",
      "5    -1.300665  -1.487007\n",
      "6    -0.953821  -0.968886\n",
      "7    -0.606977  -0.450765\n",
      "8    -0.260133   0.067356\n",
      "9    -1.647509  -2.005128\n",
      "10    0.086711   0.481852\n",
      "11    0.433555   0.689101\n",
      "12    0.780399   0.896349\n",
      "13    0.260133   0.585477\n",
      "14    0.606977   0.792725\n",
      "15    0.953821   0.999973\n",
      "16    1.300665   1.051785\n",
      "17    1.647509   1.103597\n",
      "18    1.127243   0.948161\n",
      "19    1.474087   0.844537\n",
      "MinMaxScaler Output:\n",
      "    StudyHours  TestScore\n",
      "0     0.052632   0.083333\n",
      "1     0.157895   0.250000\n",
      "2     0.263158   0.416667\n",
      "3     0.368421   0.583333\n",
      "4     0.473684   0.750000\n",
      "5     0.105263   0.166667\n",
      "6     0.210526   0.333333\n",
      "7     0.315789   0.500000\n",
      "8     0.421053   0.666667\n",
      "9     0.000000   0.000000\n",
      "10    0.526316   0.800000\n",
      "11    0.631579   0.866667\n",
      "12    0.736842   0.933333\n",
      "13    0.578947   0.833333\n",
      "14    0.684211   0.900000\n",
      "15    0.789474   0.966667\n",
      "16    0.894737   0.983333\n",
      "17    1.000000   1.000000\n",
      "18    0.842105   0.950000\n",
      "19    0.947368   0.916667\n",
      "Training Data:\n",
      "    StudyHours\n",
      "18          17\n",
      "1            4\n",
      "6            5\n",
      "12          15\n",
      "7            7\n",
      "8            9\n",
      "10          11\n",
      "16          18\n",
      "4           10\n",
      "0            2\n",
      "19          19\n",
      "13          12\n",
      "17          20\n",
      "3            8\n",
      "Testing Data:\n",
      "    StudyHours\n",
      "15          16\n",
      "14          14\n",
      "9            1\n",
      "2            6\n",
      "5            3\n",
      "11          13\n",
      "Training Data:\n",
      "    TestScore\n",
      "18         97\n",
      "1          55\n",
      "6          60\n",
      "12         96\n",
      "7          70\n",
      "8          80\n",
      "10         88\n",
      "16         99\n",
      "4          85\n",
      "0          45\n",
      "19         95\n",
      "13         90\n",
      "17        100\n",
      "3          75\n",
      "Testing Data:\n",
      "    TestScore\n",
      "15         98\n",
      "14         94\n",
      "9          40\n",
      "2          65\n",
      "5          50\n",
      "11         92\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    'StudyHours': [2, 4, 6, 8, 10, 3, 5, 7, 9, 1,\n",
    "                   11, 13, 15, 12, 14, 16, 18, 20, 17, 19],\n",
    "    'TestScore':  [45, 55, 65, 75, 85, 50, 60, 70, 80, 40,\n",
    "                   88, 92, 96, 90, 94, 98, 99, 100, 97, 95]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# STANDARD SCALER\n",
    "standard_scaler = StandardScaler()\n",
    "standard_scaled = standard_scaler.fit_transform(df)\n",
    "\n",
    "print(\"Standard Scaler Output:\")\n",
    "print(pd.DataFrame(standard_scaled, columns=['StudyHours', 'TestScore']))\n",
    "\n",
    "# MIN MAX SCALER\n",
    "minmax_scaler = MinMaxScaler()\n",
    "minmax_scaled = minmax_scaler.fit_transform(df)\n",
    "\n",
    "print(\"MinMaxScaler Output:\")\n",
    "print(pd.DataFrame(minmax_scaled, columns=['StudyHours', 'TestScore']))\n",
    "\n",
    "# TRAIN TEST SPLIT \n",
    "X = df[['StudyHours']]\n",
    "Y = df[['TestScore']]\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=44)\n",
    "print(\"Training Data:\")\n",
    "print(X_train)\n",
    "\n",
    "print(\"Testing Data:\")\n",
    "print(X_test)\n",
    "\n",
    "print(\"Training Data:\")\n",
    "print(Y_train)\n",
    "\n",
    "print(\"Testing Data:\")\n",
    "print(Y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
