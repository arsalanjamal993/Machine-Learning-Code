ðŸ“˜ K-Nearest Neighbors (KNN) â€” Supervised Learning

-------------------------------------------------------------
1) Definition
K-Nearest Neighbors (KNN) is a supervised learning algorithm that classifies or predicts data points 
based on the classes/values of their nearest neighbors.

- k = number of neighbors to consider.
- Works for both Classification (categorical labels) and Regression (continuous values).

-------------------------------------------------------------
2) Explanation
- KNN stores all the training data.
- When predicting for a new point, it calculates the distance from that point to all training samples.
- It selects the 'k' nearest points.
- For Classification â†’ majority vote of neighbors.
- For Regression â†’ average of neighborsâ€™ values.

-------------------------------------------------------------
3) Real-life Examples
- Classifying fruits based on weight and size (Apple vs Orange).
- Recommending movies based on similar user ratings.
- Predicting house prices using nearby houses.

-------------------------------------------------------------
4) Syntax (scikit-learn)
from sklearn.neighbors import KNeighborsClassifier

model = KNeighborsClassifier(n_neighbors=3)
model.fit(X_train, y_train)
y_pred = model.predict(X_test)

-------------------------------------------------------------
5) How it Works
1. Choose a value for k (e.g., 3).
2. Compute distances (commonly Euclidean) between the new point and all training points.
3. Select the k nearest neighbors.
4. Classification â†’ use majority class.
   Regression â†’ use mean value.
5. Return the result.

-------------------------------------------------------------
6) Key Concepts
- Distance Metrics: Euclidean, Manhattan, Minkowski.
- Odd values of k are preferred (to avoid ties).
- Small k â†’ Overfitting (too sensitive to noise).
- Large k â†’ Underfitting (too smooth).
- Important: Features must be scaled (Normalization/Standardization).

-------------------------------------------------------------
7) Outputs in scikit-learn
- model.predict([[new_data]]) â†’ prediction (class or value).
- model.score(X, y) â†’ accuracy (classification) or RÂ² (regression).

-------------------------------------------------------------
8) Summary
- KNN = Lazy learner (no training phase, just memorizes data).
- Simple, intuitive, but slow for very large datasets.
- Works best when:
  - Data is well-scaled
  - Classes are balanced
  - k is chosen carefully (âˆšn rule + cross-validation)

